---
title: "Default Prediction in Co-Branded Credit Card - EDA"
output:
  html_document:
    df_print: paged
---

## Loading libraries
Let's begin by loading required libraries.

```{r message=FALSE, warning=FALSE}
library(tidyverse) # several utility packages
library(DataExplorer) # automated EDA
library(Amelia) # missing map
library(Hmisc) # missing values imputation
library(corrplot) # correlation plot
library(gridExtra) # Multipanel plots
library(caret) # Classification & Regression Trees
library(e1071) # Machine Learning Models
library(pROC) # Plotting ROC Curve

options(scipen = 9999)
```

## Loading & Understanding Data

Let's load our dataset and store it in a dataframe. When we opened our dataset in excel, we saw that missing values are denoted by different characters. We will use those while loading our dataset.

```{r}
card_data <- read.csv("Training_dataset_Original.csv", 
                      na.strings = c("na", "N/A", "missing"))
```

Let's take a quick look at the dataset.

```{r}
dim(card_data)

head(card_data)

tail(card_data)
```

We can see that the dataset has 80000 observations and 49 variables. We also have some missing values in our dataset. Let's take a look at the structure and summary of the dataset.

```{r}
glimpse(card_data)
```

```{r}
describe(card_data)
```

Following observations can be made:

+ *Application_key* is just a unique number given to each application/client.
+ Most of the variables are numeric, in fact there is only one factor variable **mvar47**.
+ **default_ind** is our dependent variable, which we are interested in predicting.
+ The dependent variable is loaded as *numeric*, it should be a *factor*.
+ The mean of **default_ind** is 0.2462, indicating that the mean default rate is 24.62%.
+ *mvar16-mvar20* are basically counts, we can consider them as a factor variable.
+ *mvar34-mvar39* are basically counts, we can consider them as a factor variable.
+ *mvar45-mvar46* are basically counts, we can consider them as a factor variable.
+ Many variables are heavily skewed and thus may require transformation.
+ There are a lot of missing values in the dataset.

Let's drop the *application_key* and convert dependent variable to factor.

```{r}
card_data$application_key <- NULL
card_data$default_ind <- as.factor(card_data$default_ind)
```

**mvar16-mvar20**

Let's convert these variables to factor. But before that let's impute missing values in these variables with "0".

```{r}
card_data[which(is.na(card_data$mvar16)), "mvar16"] <- 0
card_data[which(is.na(card_data$mvar17)), "mvar17"] <- 0
card_data[which(is.na(card_data$mvar18)), "mvar18"] <- 0
card_data[which(is.na(card_data$mvar19)), "mvar19"] <- 0
card_data[which(is.na(card_data$mvar20)), "mvar20"] <- 0
```

Now converting the variables to factor.

```{r}
card_data$mvar16 <- as.factor(ifelse(card_data$mvar16 == 0, 0, ifelse(card_data$mvar16 == 1, 1, 2)))

card_data$mvar17 <- as.factor(ifelse(card_data$mvar17 == 0, 0, ifelse(card_data$mvar17 == 1, 1, 2)))

card_data$mvar18 <- as.factor(ifelse(card_data$mvar18 == 0, 0, ifelse(card_data$mvar18 == 1, 1, 2)))

card_data$mvar19 <- as.factor(ifelse(card_data$mvar19 == 0, 0, ifelse(card_data$mvar19 == 1, 1, 2)))

card_data$mvar20 <- as.factor(ifelse(card_data$mvar20 == 0, 0, ifelse(card_data$mvar20 == 1, 1, 2)))
```

**mvar34-mvar39**

Since, *mvar36*, *mvar37* & *mvar38* have too many unique values, let's convert only other variables to factor. Before that let's impute missing values.

```{r}
card_data[which(is.na(card_data$mvar34)), "mvar34"] <- 0
card_data[which(is.na(card_data$mvar35)), "mvar35"] <- 0
card_data[which(is.na(card_data$mvar39)), "mvar39"] <- 0
```

Now converting to factor variables.

```{r}
card_data$mvar34 <- as.factor(ifelse(card_data$mvar34 == 0, 0, ifelse(card_data$mvar34 == 1, 1, 2)))

card_data$mvar35 <- as.factor(ifelse(card_data$mvar35 == 0, 0, ifelse(card_data$mvar35 == 1, 1, 2)))

card_data$mvar39 <- as.factor(ifelse(card_data$mvar39 == 0, 0, ifelse(card_data$mvar39 == 1, 1, 2)))
```

**mvar45-mvar46**

```{r}
card_data[which(is.na(card_data$mvar45)), "mvar45"] <- 0
card_data[which(is.na(card_data$mvar46)), "mvar46"] <- 0
```

Now converting to factor variables.

```{r}
card_data$mvar45 <- as.factor(ifelse(card_data$mvar45 == 0, 0, 1))

card_data$mvar46 <- as.factor(ifelse(card_data$mvar46 == 0, 0, 1))
```

## Missing Values

Let's see how many missing values are there in the dataset.

```{r}
# missing values per column
missing_per_column <- colSums(sapply(card_data, is.na))
sort(missing_per_column[missing_per_column > 0], decreasing = T)
```

Let's visualize the above information.

```{r fig.width=18}
plot_missing(card_data)
```

We can see that some of the variables have more than 40% missing values. This is not good and we need to choose appropriate strategy to handle missing values. Let's see the relative positions of these missing value in another plot.

```{r fig.width=18}
missmap(card_data, col = c("black", "blue"))
```

We can see that the missing values are not missing randomly. We will have to choose our imputation strategy keeping this in mind.

## EDA

Let's begin our EDA by looking at our dependent variable first.

### Dependent Variable - default_ind

Let's see the distribution of our dependent variable first.

```{r}
prop.table(table(card_data$default_ind))
```

Average default rate for our dataset is around 25%. 

### Independent Variables
Now, we shall look at our independent variables one by one. We will look at univariate as well as bivariate plots of the independent variables w.r.t. our target variable. Let's begin by looking at our only factor variable present in the dataset.

#### Categorical Independent Variable - mvar16-mvar20

Let's see its frequency distribution first.

```{r}
prop.table(table(card_data$mvar16))
prop.table(table(card_data$mvar17))
prop.table(table(card_data$mvar18))
prop.table(table(card_data$mvar19))
prop.table(table(card_data$mvar20))
```

Let's see whether default rates are different for different levels of these variables.

```{r}
p1 <- card_data %>% ggplot(aes(mvar16, fill = default_ind)) + geom_bar(position = "fill")
p2 <- card_data %>% ggplot(aes(mvar17, fill = default_ind)) + geom_bar(position = "fill")
p3 <- card_data %>% ggplot(aes(mvar18, fill = default_ind)) + geom_bar(position = "fill")
p4 <- card_data %>% ggplot(aes(mvar19, fill = default_ind)) + geom_bar(position = "fill")
p5 <- card_data %>% ggplot(aes(mvar20, fill = default_ind)) + geom_bar(position = "fill")

grid.arrange(p1, p2, p3, p4, p5, ncol = 2)
```

#### Categorical Independent Variable - mvar34, mvar35 & mvar39

Let's see its frequency distribution first.

```{r}
prop.table(table(card_data$mvar34))
prop.table(table(card_data$mvar35))
prop.table(table(card_data$mvar39))
```

Let's see whether default rates are different for different levels of these variables.

```{r}
p1 <- card_data %>% ggplot(aes(mvar34, fill = default_ind)) + geom_bar(position = "fill")
p2 <- card_data %>% ggplot(aes(mvar35, fill = default_ind)) + geom_bar(position = "fill")
p3 <- card_data %>% ggplot(aes(mvar39, fill = default_ind)) + geom_bar(position = "fill")

grid.arrange(p1, p2, p3, ncol = 2)
```

#### Categorical Independent Variable - mvar45-mvar46

Let's see its frequency distribution first.

```{r}
prop.table(table(card_data$mvar45))
prop.table(table(card_data$mvar46))
```

Let's see whether default rates are different for different levels of these variables.

```{r fig.height=3, fig.width=8}
p1 <- card_data %>% ggplot(aes(mvar45, fill = default_ind)) + geom_bar(position = "fill")
p2 <- card_data %>% ggplot(aes(mvar46, fill = default_ind)) + geom_bar(position = "fill")

grid.arrange(p1, p2, ncol = 2)
```

#### Categorical Independent Variable - mvar47

According to the data description, this is the type of product that the applicant applied for. It has only two levels("C" - Charge & "L" - Lending). Let's see its frequency distribution first.

```{r}
prop.table(table(card_data$mvar47))
```

Around 65% of the applicants applied for product type "C". Let's see whether default rates are different for these two product types.

```{r fig.height=4}
card_data %>% ggplot(aes(mvar47, fill = default_ind)) + geom_bar(position = "fill")
```

Indeed, default rates are quite higher for product type "C". Let's move on to remaining numeric independent variables now.

#### Numeric Independent Variables

##### Density Plots

Let's see the distribution of each independent variable with respect to the target variable "default_ind'.

```{r fig.height=5, fig.width=8}
plot_density(card_data, ncol = 3, nrow = 3, ggtheme = theme_bw())
```

##### Boxplots

Now, let's see the bivarite plot of each independent variable w.r.t. our dependent variable.

```{r message=FALSE, warning=FALSE}
plot_boxplot(card_data, by = "default_ind", geom_boxplot_args = list(fill = "blue"), 
             ncol = 3, nrow = 2)
```

Following inference can be made after looking at the above plots:

+ *mvar1* i.e. credit worthiness score for idividuals who defaulted, is low compared to individual who didn't.
+ *mvar21 - mvar23* has an impact on default. Average utilization is higher for people who defaulted.
+ *mvar25 - mvar32* have an impact on default rate. These variables measure the tenure of credit cards. The individuals who defaulted, generally have a lower tenure.
+ *mvar33* has an impact on default rate. This variable measures the duration of stay at current residential address. Generally, people who defaulted have low duration of stay at their present address.
+ *mvar37* has an impact on default rate. This variables indicates the number od credit cards with an active tenure of at least two years. The individuals who defaulted, have less average tenure.
+ *mvar41* has an impact on default rate. This variable measures the utilization of line on active auto loans. People who defaulted have higher utilization.
+ *mvar42* has an impact on default rate. This variable measures the financial stress of the borrower. Higher the financial stress a borrower has, higher is the chances of default.
+ *mvar43* has an impact on default rate. This variable measures the number of credit lines on which borrower has never missed a payment in last 2 years.  
+ *mvar44* has an impact on defsult rate. This variable measures the ratio of maximum amount due and total amount due on all active credit lines. Higher the ratio, less is the chances of default.
    
We saw that many variables present in the dataset are measuring similar things like - utilization, amount of credit etc. So we expect that those variables might have a high correlation among themselves. Let's check that.

### Correlations

Let's visualize the correlations between independent variables.

```{r fig.height=18, fig.width=18}
cor_matrix <- card_data %>% select_if(is.numeric) %>% cor(use = "pairwise.complete.obs")
corrplot.mixed(cor_matrix, upper = "circle", lower = "number", tl.pos = "lt")
```

We can see that there is some strong correlation between some of the independent variables. Let's take a closer look at the variables which are highly correlated.

```{r}
high_correlations <- findCorrelation(cor_matrix, cutoff = 0.8, verbose = T, names = T)
```

We can see that following variables have high correlations:

+ *mvar32* & *mvar37* 
+ *mvar27* & *mvar26* 
+ *mvar10* & *mvar7* 
+ *mavr22* & *mvar23* 

We will be dropping variables from these pairs to avoid multicollinearity in the model.

### Dropping Insignificant Variables

Now, that we have completed our EDA process, let's drop variables which are insignificant in predicting *default_ind*.

```{r}
vars_to_keep <- c("mvar1", "mvar16", "mvar17", "mvar18", "mvar19", "mvar20", "mvar21", 
                  "mvar23", "mvar25", "mvar26", "mvar28", "mvar29", "mvar30", "mvar31",
                  "mvar33", "mvar34", "mvar35", "mvar37", "mvar39", "mvar41", "mvar42", 
                  "mvar43", "mvar44", "mvar45", "mvar46", "mvar47", "default_ind")

card_data_reduced <- card_data[ ,vars_to_keep]

write.csv(card_data_reduced, file = "Reduced_Dataset.csv", row.names = F)

str(card_data_reduced)
```

Now we have a much manageabale dataframe and we can proceed with our model building.
